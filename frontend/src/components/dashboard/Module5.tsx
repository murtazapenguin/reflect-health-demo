import { useState, useRef, useCallback } from "react";
import { supabase } from "@/integrations/supabase/client";
import {
  Upload, FileAudio, Loader2, CheckCircle2, AlertCircle, Brain, Shield,
  TrendingUp, ChevronDown, ChevronUp, BarChart3, BookOpen, Cpu, Play, Pause, Square,
  RotateCcw, Database, Users, DollarSign, Layers, Mic,
} from "lucide-react";
import penguinLogo from "@/assets/penguin-ai-logo.png";
import { AutomationScoringPanel, type ScoringBreakdown } from "@/components/dashboard/AutomationScoringPanel";
import { BatchAnalysisMode } from "@/components/dashboard/BatchAnalysisMode";
import { LiveSimulationMode } from "@/components/dashboard/LiveSimulationMode";

// â”€â”€â”€ Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
type AnalysisState = "idle" | "uploading" | "transcribing" | "analyzing" | "complete" | "error";

interface SpeakerWord { text: string; start: number; end: number; speaker: string; }
interface SpeakerTurn { role: "caller" | "ai"; text: string; startTime: number; endTime: number; }

interface CallAnalysis {
  id?: string;
  recordingId?: string;
  transcript: string;
  speakerWords?: SpeakerWord[];
  call_type: string;
  intent: string;
  entities: {
    member_id?: string | null; dob?: string | null; policy_number?: string | null;
    claim_number?: string | null; cpt_codes?: string[]; icd_codes?: string[];
    provider_npi?: string | null; address_update?: boolean;
  };
  sentiment: string;
  resolution_type: string;
  automation_feasibility_score: number;
  escalation_risk: string;
  summary: string;
  backend_systems_accessed: string[];
  compliance_flags: string[];
  ai_response_script: string;
  automation_scenario_name: string;
  required_data_inputs: string[];
  required_system_integrations: string[];
  escalation_rules: string[];
  compliance_requirements: string[];
  expected_resolution: string;
  avg_handle_time_seconds?: number;
  cost_per_call_manual?: number;
  cost_per_call_ai?: number;
  scoring_breakdown?: ScoringBreakdown;
}

interface SavedScenario {
  id: string; name: string; intent: string;
  confidence_score: number; automation_coverage_before: number; automation_coverage_after: number;
}

// â”€â”€â”€ Micro helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function StatusStep({ label, status }: { label: string; status: "pending" | "active" | "done" | "error" }) {
  return (
    <div className={`flex items-center gap-2 text-[11px] ${status === "done" ? "text-emerald-600" : status === "active" ? "text-primary" : status === "error" ? "text-destructive" : "text-muted-foreground"}`}>
      {status === "done" ? <CheckCircle2 className="h-3 w-3" /> : status === "active" ? <Loader2 className="h-3 w-3 animate-spin" /> : status === "error" ? <AlertCircle className="h-3 w-3" /> : <div className="h-3 w-3 rounded-full border border-current opacity-30" />}
      {label}
    </div>
  );
}

function RiskBadge({ level }: { level: string }) {
  const c = level === "Low" ? "text-emerald-600 bg-emerald-50 border-emerald-200" : level === "Medium" ? "text-amber-600 bg-amber-50 border-amber-200" : "text-destructive bg-red-50 border-red-200";
  return <span className={`text-[9px] font-semibold px-1.5 py-0.5 rounded border ${c}`}>{level}</span>;
}

function SentimentBadge({ sentiment }: { sentiment: string }) {
  const c = sentiment === "Positive" ? "text-emerald-600 bg-emerald-50 border-emerald-200" : sentiment === "Neutral" ? "text-blue-600 bg-blue-50 border-blue-200" : sentiment === "Frustrated" ? "text-amber-600 bg-amber-50 border-amber-200" : "text-destructive bg-red-50 border-red-200";
  return <span className={`text-[9px] font-semibold px-1.5 py-0.5 rounded border ${c}`}>{sentiment}</span>;
}

// â”€â”€â”€ Audio utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function encodeWav(buffer: AudioBuffer): ArrayBuffer {
  const ch = buffer.numberOfChannels, sr = buffer.sampleRate, bps = 16;
  const ba = (ch * bps) / 8, br = sr * ba, dl = buffer.length * ba;
  const ab = new ArrayBuffer(44 + dl); const v = new DataView(ab);
  const ws = (o: number, s: string) => { for (let i = 0; i < s.length; i++) v.setUint8(o + i, s.charCodeAt(i)); };
  ws(0, "RIFF"); v.setUint32(4, 36 + dl, true); ws(8, "WAVE"); ws(12, "fmt ");
  v.setUint32(16, 16, true); v.setUint16(20, 1, true); v.setUint16(22, ch, true);
  v.setUint32(24, sr, true); v.setUint32(28, br, true); v.setUint16(32, ba, true);
  v.setUint16(34, bps, true); ws(36, "data"); v.setUint32(40, dl, true);
  let o = 44;
  for (let i = 0; i < buffer.length; i++) {
    for (let c2 = 0; c2 < ch; c2++) {
      const s = Math.max(-1, Math.min(1, buffer.getChannelData(c2)[i]));
      v.setInt16(o, s < 0 ? s * 0x8000 : s * 0x7fff, true); o += 2;
    }
  }
  return ab;
}

async function sliceAudio(buf: AudioBuffer, t0: number, t1: number): Promise<string | null> {
  try {
    const sr = buf.sampleRate;
    const s0 = Math.max(0, Math.floor(t0 * sr));
    const s1 = Math.min(buf.length, Math.ceil(t1 * sr));
    if (s1 <= s0) return null;
    const ctx = new AudioContext();
    const slice = ctx.createBuffer(buf.numberOfChannels, s1 - s0, sr);
    for (let c = 0; c < buf.numberOfChannels; c++) slice.copyToChannel(buf.getChannelData(c).subarray(s0, s1), c);
    await ctx.close();
    return URL.createObjectURL(new Blob([encodeWav(slice)], { type: "audio/wav" }));
  } catch { return null; }
}

async function playUrl(url: string, vol = 0.85, audioRef?: React.MutableRefObject<HTMLAudioElement | null>, pauseRef?: React.MutableRefObject<boolean>): Promise<void> {
  return new Promise(res => {
    const a = new Audio(url);
    a.volume = vol;
    if (audioRef) audioRef.current = a;
    a.onended = () => { if (audioRef) audioRef.current = null; res(); };
    a.onerror = () => { if (audioRef) audioRef.current = null; res(); };
    a.play().catch(() => res());
  });
}

async function fetchTTS(text: string): Promise<string | null> {
  try {
    const r = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/elevenlabs-tts`, {
      method: "POST",
      headers: { "Content-Type": "application/json", apikey: import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY, Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}` },
      body: JSON.stringify({ text, voiceId: "onwK4e9ZLuTAKqWW03F9" }),
    });
    return r.ok ? URL.createObjectURL(await r.blob()) : null;
  } catch { return null; }
}

// â”€â”€â”€ VoiceReplayPanel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
type TurnDisplay = { role: "caller" | "ai"; text: string; state: "pending" | "playing" | "done" };

interface ReplaySavings {
  originalTimeSec: number;
  aiTimeSec: number;
  savedSec: number;
  savedPct: number;
  costManual: number;
  costAI: number;
  savedCost: number;
}

async function fetchAlignedDialogue(
  callerTurns: string[],
  analysis: CallAnalysis
): Promise<string[]> {
  try {
    const res = await fetch(
      `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/generate-replay-dialogue`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          apikey: import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY,
          Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
        },
        body: JSON.stringify({
          callerTurns,
          callType: analysis.call_type,
          intent: analysis.intent,
          entities: analysis.entities,
          summary: analysis.summary,
        }),
      }
    );
    if (!res.ok) return [];
    const { responses } = await res.json();
    return Array.isArray(responses) ? responses : [];
  } catch {
    return [];
  }
}

function buildSegments(words: SpeakerWord[]) {
  const segs: { speaker: string; text: string; startTime: number; endTime: number }[] = [];
  if (!words.length) return { segs, agentSpeaker: "" };

  let cur = words[0].speaker, s0 = words[0].start, s1 = words[0].end, txt = words[0].text;
  for (let i = 1; i < words.length; i++) {
    const w = words[i];
    if (w.speaker === cur) { s1 = w.end; txt += w.text; }
    else {
      if (txt.trim()) segs.push({ speaker: cur, text: txt.trim(), startTime: s0, endTime: s1 });
      cur = w.speaker; s0 = w.start; s1 = w.end; txt = w.text;
    }
  }
  if (txt.trim()) segs.push({ speaker: cur, text: txt.trim(), startTime: s0, endTime: s1 });

  // Identify agent vs caller speaker
  const agentPhrases = /how can i (help|assist)|thank you for calling|this is .{2,20} (from|with|at)|your (account|policy|claim|coverage|member|benefit)|let me (pull|look|check|verify)|i('ve| have) (located|found|confirmed|verified)|have a great|is there anything else/i;
  const scores: Record<string, number> = {};
  for (const seg of segs) {
    if (!scores[seg.speaker]) scores[seg.speaker] = 0;
    if (agentPhrases.test(seg.text)) scores[seg.speaker]++;
  }

  const allSpeakers = [...new Set(segs.map(s => s.speaker))];
  let agentSpeaker = allSpeakers[0];
  let topScore = -1;
  for (const sp of allSpeakers) {
    const sc = scores[sp] ?? 0;
    if (sc > topScore) { topScore = sc; agentSpeaker = sp; }
  }
  // Default: speaker_0 answered first = agent
  if (topScore <= 0) agentSpeaker = allSpeakers[0];

  return { segs, agentSpeaker };
}

function VoiceReplayPanel({ analysis, audioFile }: { analysis: CallAnalysis; audioFile: File | null }) {
  const [turns, setTurns] = useState<TurnDisplay[]>([]);
  const [playing, setPlaying] = useState(false);
  const [paused, setPaused] = useState(false);
  const [completed, setCompleted] = useState(false);
  const [overlays, setOverlays] = useState<string[]>([]);
  const [loadingDialogue, setLoadingDialogue] = useState(false);
  const [savings, setSavings] = useState<ReplaySavings | null>(null);
  const abortRef = useRef(false);
  const pauseRef = useRef(false);
  const bufRef = useRef<AudioBuffer | null>(null);
  const activeAudioRef = useRef<HTMLAudioElement | null>(null);
  const replayStartRef = useRef<number>(0);

  const OVERLAYS = ["âœ” Intent Identified", "âœ” Member ID Validated", "âœ” Data Retrieved", "âœ” Backend Systems Queried", "âœ” Compliance Log Created", "âœ” CRM Updated"];
  const TASKS = [{ e: "ğŸ§¾", l: "Call summary generated" }, { e: "ğŸ—‚", l: "Structured data packet created" }, { e: "ğŸ“‹", l: "CRM record updated" }, { e: "ğŸ“¤", l: "Claims system notified" }, { e: "âœ‰ï¸", l: "Follow-up email queued" }, { e: "ğŸ“±", l: "SMS confirmation sent" }];

  const runReplay = useCallback(async () => {
    abortRef.current = false;
    pauseRef.current = false;
    setPlaying(true); setPaused(false); setCompleted(false); setOverlays([]);
    setSavings(null);
    replayStartRef.current = Date.now();

    // Decode audio once
    if (!bufRef.current && audioFile) {
      try {
        const ab = await audioFile.arrayBuffer();
        const ctx = new AudioContext();
        bufRef.current = await ctx.decodeAudioData(ab);
        await ctx.close();
      } catch { console.warn("Could not decode audio"); }
    }

    // Build segments from speaker words
    const words = analysis.speakerWords || [];
    let baseConversation: SpeakerTurn[] = [];

    if (words.length > 0) {
      const { segs, agentSpeaker } = buildSegments(words);
      // Extract caller turns in order
      const callerSegs = segs.filter(s => s.speaker !== agentSpeaker);
      const callerTexts = callerSegs.map(s => s.text);

      // Fetch aligned AI responses: one per caller turn PLUS an opening greeting
      setLoadingDialogue(true);
      const aiResponses = await fetchAlignedDialogue(callerTexts, analysis);
      setLoadingDialogue(false);

      if (abortRef.current) { setPlaying(false); return; }

      // NEW ORDER: Penguin AI greeting â†’ caller turn 1 â†’ AI response 1 â†’ caller turn 2 â†’ AI response 2 â€¦
      // The first element of aiResponses is the opening greeting (before any caller turn)
      const openingGreeting = aiResponses[0] ?? "Thank you for calling. How can I assist you today?";
      const turnResponses = aiResponses.slice(1); // responses that follow each caller utterance

      // Opening AI greeting
      baseConversation.push({ role: "ai", text: openingGreeting, startTime: 0, endTime: 0 });

      // Then interleave: caller speaks â†’ AI responds
      for (let i = 0; i < callerSegs.length; i++) {
        const callerSeg = callerSegs[i];
        baseConversation.push({ role: "caller", text: callerSeg.text, startTime: callerSeg.startTime, endTime: callerSeg.endTime });
        const aiText = turnResponses[i];
        if (aiText) {
          baseConversation.push({ role: "ai", text: aiText, startTime: 0, endTime: 0 });
        }
      }
    } else {
      // Fallback: transcript-based
      const lines = analysis.transcript.split('\n').filter(Boolean);
      const callerLines = lines.filter(l => /^(caller|member|provider|patient|customer):/i.test(l)).map(l => l.replace(/^[^:]+:\s*/i, '').trim());
      const aiSentences = (analysis.ai_response_script.match(/[^.!?]+[.!?]+/g) || [analysis.ai_response_script]).map(s => s.trim()).filter(Boolean);

      setLoadingDialogue(true);
      const aiResponses = callerLines.length > 0
        ? await fetchAlignedDialogue(callerLines, analysis)
        : aiSentences;
      setLoadingDialogue(false);

      if (abortRef.current) { setPlaying(false); return; }

      // Opening greeting from first AI response, then caller â†’ AI pairs
      const openingGreeting = aiResponses[0] ?? "Thank you for calling. How can I assist you today?";
      const turnResponses = aiResponses.slice(1);
      baseConversation.push({ role: "ai", text: openingGreeting, startTime: 0, endTime: 0 });
      for (let i = 0; i < callerLines.length; i++) {
        baseConversation.push({ role: "caller", text: callerLines[i], startTime: i * 9, endTime: i * 9 + 7 });
        if (turnResponses[i]) baseConversation.push({ role: "ai", text: turnResponses[i], startTime: 0, endTime: 0 });
      }
    }

    const conversation = baseConversation;
    setTurns(conversation.map(t => ({ role: t.role, text: t.text, state: "pending" })));

    let oidx = 0;
    for (let i = 0; i < conversation.length; i++) {
      if (abortRef.current) break;

      // Pause: wait until unpaused or aborted
      while (pauseRef.current && !abortRef.current) {
        await new Promise(r => setTimeout(r, 100));
      }
      if (abortRef.current) break;

      const turn = conversation[i];
      setTurns(prev => prev.map((t, idx) => idx === i ? { ...t, state: "playing" } : t));

      if (turn.role === "caller") {
        let played = false;
        if (bufRef.current && turn.endTime > turn.startTime) {
          const url = await sliceAudio(bufRef.current, turn.startTime, turn.endTime);
          if (url) { await playUrl(url, 0.9, activeAudioRef); URL.revokeObjectURL(url); played = true; }
        }
        if (!played) await new Promise(r => setTimeout(r, Math.max(1200, turn.text.length * 42)));
      } else {
        if (oidx < OVERLAYS.length) setOverlays(prev => [...prev, OVERLAYS[oidx++]]);
        const ttsUrl = await fetchTTS(turn.text);
        if (ttsUrl) { await playUrl(ttsUrl, 0.8, activeAudioRef); URL.revokeObjectURL(ttsUrl); }
        else await new Promise(r => setTimeout(r, Math.max(1000, turn.text.length * 38)));
      }

      if (abortRef.current) break;
      setTurns(prev => prev.map((t, idx) => idx === i ? { ...t, state: "done" } : t));
      await new Promise(r => setTimeout(r, 220));
    }

    while (oidx < OVERLAYS.length && !abortRef.current) { setOverlays(prev => [...prev, OVERLAYS[oidx++]]); await new Promise(r => setTimeout(r, 300)); }
    // Calculate savings: original call duration vs AI replay duration
    if (!abortRef.current) {
      const aiTimeSec = (Date.now() - replayStartRef.current) / 1000;
      const originalTimeSec = analysis.avg_handle_time_seconds || 360;
      const savedSec = Math.max(0, originalTimeSec - aiTimeSec);
      const savedPct = originalTimeSec > 0 ? (savedSec / originalTimeSec) * 100 : 0;
      const costManual = analysis.cost_per_call_manual ?? 4.50;
      const costAI = analysis.cost_per_call_ai ?? 0.65;
      setSavings({ originalTimeSec, aiTimeSec, savedSec, savedPct, costManual, costAI, savedCost: costManual - costAI });
      setCompleted(true);
    }
    setPlaying(false); setPaused(false);
  }, [audioFile, analysis]);

  const handlePause = () => {
    if (activeAudioRef.current) activeAudioRef.current.pause();
    pauseRef.current = true;
    setPaused(true);
  };

  const handleResume = () => {
    if (activeAudioRef.current) activeAudioRef.current.play().catch(() => {});
    pauseRef.current = false;
    setPaused(false);
  };

  const handleStop = () => {
    abortRef.current = true;
    pauseRef.current = false;
    if (activeAudioRef.current) { activeAudioRef.current.pause(); activeAudioRef.current = null; }
    setPlaying(false); setPaused(false); setCompleted(false);
    setTurns([]); setOverlays([]);
  };

  return (
    <div className="rounded-lg border border-border bg-card overflow-hidden">
      <div className="px-4 py-3 border-b border-border bg-secondary/20 flex items-center justify-between">
        <div className="flex items-center gap-2">
          <Play className="h-3.5 w-3.5 text-primary" />
          <span className="text-xs font-semibold text-foreground">Penguin AI â€” Automated Scenario Replay</span>
          {audioFile && <span className="text-[9px] text-emerald-700 border border-emerald-200 bg-emerald-50 rounded px-1.5 py-0.5 font-medium">Real caller audio</span>}
        </div>
        {/* Playback controls */}
        <div className="flex items-center gap-1.5">
          {playing && !paused && (
            <button onClick={handlePause} title="Pause" className="p-1.5 rounded bg-secondary hover:bg-secondary/80 text-foreground transition-colors">
              <Pause className="h-3 w-3" />
            </button>
          )}
          {playing && paused && (
            <button onClick={handleResume} title="Resume" className="p-1.5 rounded bg-primary/10 hover:bg-primary/20 text-primary transition-colors">
              <Play className="h-3 w-3" />
            </button>
          )}
          {(playing || completed) && (
            <button onClick={handleStop} title="Stop" className="p-1.5 rounded bg-secondary hover:bg-destructive/10 hover:text-destructive text-muted-foreground transition-colors">
              <Square className="h-3 w-3" />
            </button>
          )}
          {completed && (
            <button onClick={() => { handleStop(); setTimeout(runReplay, 50); }} title="Replay" className="p-1.5 rounded bg-secondary hover:bg-secondary/80 text-muted-foreground hover:text-foreground transition-colors">
              <RotateCcw className="h-3 w-3" />
            </button>
          )}
        </div>
      </div>

      <div className="p-4 space-y-3">
        {/* Loading aligned dialogue indicator */}
        {loadingDialogue && (
          <div className="flex items-center justify-center gap-2 py-3 text-[10px] text-primary">
            <Loader2 className="h-3.5 w-3.5 animate-spin" />
            Generating Penguin AI aligned responsesâ€¦
          </div>
        )}

        {!playing && !completed && (
          <>
            <p className="text-[10px] text-muted-foreground text-center leading-relaxed">
              {audioFile
                ? "The caller's actual voice (extracted from your recording) plays on the left. Penguin AI synthesized voice responds on the right â€” showing exactly how the bot would have handled this call."
                : "Simulated conversation using transcript timing. Upload a real audio file to hear the actual caller voice."}
            </p>
            <button onClick={runReplay} className="w-full py-2.5 rounded-lg reflect-gradient text-white text-xs font-semibold flex items-center justify-center gap-2 hover:opacity-90 transition-opacity">
              <Play className="h-3.5 w-3.5 fill-current" />
              {audioFile ? "Play: Real Caller Voice + Penguin AI Response" : "Play: Simulated Scenario Replay"}
            </button>
          </>
        )}

        {/* Paused indicator */}
        {paused && (
          <div className="flex items-center justify-center gap-2 py-1 text-[10px] text-muted-foreground">
            <Pause className="h-3 w-3" /> Paused â€” click play to resume
          </div>
        )}

        {/* Interleaved conversation */}
        {turns.length > 0 && (
          <div className="space-y-2 max-h-72 overflow-y-auto pr-1">
            {turns.map((turn, i) => (
              <div key={i} className={`flex gap-2 items-start ${turn.role === "ai" ? "flex-row" : "flex-row-reverse"}`}>
                <div className={`w-6 h-6 rounded-full flex items-center justify-center shrink-0 mt-0.5 ${turn.role === "ai" ? "bg-primary/10" : "bg-secondary"}`}>
                  {turn.role === "ai" ? <img src={penguinLogo} alt="AI" className="h-3.5 w-3.5 object-contain" /> : <Users className="h-3 w-3 text-muted-foreground" />}
                </div>
                <div className={`rounded-lg px-2.5 py-2 max-w-[78%] border text-[10px] leading-relaxed transition-all duration-200 ${
                  turn.state === "playing" ? (turn.role === "ai" ? "border-primary/40 bg-primary/10 shadow-sm" : "border-amber-300 bg-amber-50/60 shadow-sm")
                    : turn.state === "done" ? "border-border bg-secondary/30 opacity-80" : "border-border/30 bg-secondary/10 opacity-35"
                }`}>
                  <div className="flex items-center gap-1 mb-0.5">
                    <span className={`text-[9px] font-semibold uppercase tracking-wide ${turn.role === "ai" ? "text-primary" : "text-muted-foreground"}`}>
                      {turn.role === "ai" ? "Penguin AI" : "Caller"}
                    </span>
                    {turn.state === "playing" && !paused && (
                      <span className="flex gap-0.5 ml-1">
                        {[0, 1, 2, 3].map(j => <span key={j} className={`inline-block w-0.5 rounded-full ${turn.role === "ai" ? "bg-primary" : "bg-amber-500"} animate-pulse`} style={{ height: `${6 + (j % 3) * 3}px`, animationDelay: `${j * 0.1}s` }} />)}
                      </span>
                    )}
                    {turn.state === "done" && <CheckCircle2 className="h-2.5 w-2.5 text-emerald-500 ml-1" />}
                  </div>
                  <p className="text-foreground">{turn.text}</p>
                </div>
              </div>
            ))}
          </div>
        )}

        {/* AI overlays */}
        {overlays.length > 0 && (
          <div className="flex flex-wrap gap-1.5">
            {overlays.map((o, i) => <span key={i} className="text-[9px] font-medium text-emerald-700 bg-emerald-50 border border-emerald-200 rounded px-1.5 py-0.5 animate-in fade-in duration-300">{o}</span>)}
          </div>
        )}

        {/* Task execution + savings */}
        {completed && (
          <div className="space-y-3">
            <div className="rounded-lg border border-border bg-secondary/10 p-3">
              <div className="text-[10px] font-semibold text-foreground mb-2 flex items-center gap-1.5">
                <Cpu className="h-3 w-3 text-primary" /> End-to-End Task Execution â€” Completed Automatically
              </div>
              <div className="grid grid-cols-2 gap-1.5">
                {TASKS.map((t, i) => (
                  <div key={i} className="flex items-center gap-1.5 text-[10px] text-foreground animate-in fade-in duration-300" style={{ animationDelay: `${i * 120}ms` }}>
                    <span>{t.e}</span><span>{t.l}</span>
                  </div>
                ))}
              </div>
            </div>

            {/* Time & Cost Savings Summary */}
            {savings && (
              <div className="rounded-lg border border-emerald-200 bg-emerald-50/60 p-3 space-y-2">
                <div className="text-[10px] font-semibold text-emerald-800 flex items-center gap-1.5">
                  <TrendingUp className="h-3 w-3" /> Penguin AI vs. Human Agent â€” This Call
                </div>
                <div className="grid grid-cols-3 gap-2 text-center">
                  <div className="bg-card rounded-md p-2 border border-border">
                    <div className="text-sm font-bold text-muted-foreground">{Math.round(savings.originalTimeSec)}s</div>
                    <div className="text-[9px] text-muted-foreground">Human Handle Time</div>
                  </div>
                  <div className="bg-card rounded-md p-2 border border-emerald-200">
                    <div className="text-sm font-bold text-emerald-700">{Math.round(savings.aiTimeSec)}s</div>
                    <div className="text-[9px] text-muted-foreground">Penguin AI Time</div>
                  </div>
                  <div className="bg-card rounded-md p-2 border border-emerald-200">
                    <div className="text-sm font-bold text-emerald-700">{Math.round(savings.savedPct)}%</div>
                    <div className="text-[9px] text-muted-foreground">Faster</div>
                  </div>
                </div>
                <div className="grid grid-cols-3 gap-2 text-center">
                  <div className="bg-card rounded-md p-2 border border-border">
                    <div className="text-sm font-bold text-destructive">${savings.costManual.toFixed(2)}</div>
                    <div className="text-[9px] text-muted-foreground">Manual Cost</div>
                  </div>
                  <div className="bg-card rounded-md p-2 border border-emerald-200">
                    <div className="text-sm font-bold text-emerald-700">${savings.costAI.toFixed(2)}</div>
                    <div className="text-[9px] text-muted-foreground">AI Cost</div>
                  </div>
                  <div className="bg-card rounded-md p-2 border border-emerald-200">
                    <div className="text-sm font-bold text-emerald-700">${savings.savedCost.toFixed(2)}</div>
                    <div className="text-[9px] text-muted-foreground">Saved / Call</div>
                  </div>
                </div>
                <div className="text-center pt-1 border-t border-emerald-100">
                  <span className="text-[10px] text-emerald-700 font-medium">
                    At 5,000 calls/mo â†’ <span className="font-bold text-emerald-800">${(savings.savedCost * 5000 * 12 / 1000).toFixed(0)}K annual savings</span>
                  </span>
                </div>
              </div>
            )}
          </div>
        )}
      </div>
    </div>
  );
}

// â”€â”€â”€ Impact Dashboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function ImpactDashboard({ scenarios }: { scenarios: SavedScenario[] }) {
  const n = scenarios.length;
  const cov = n > 0 ? Math.min(64 + n * 7, 97) : 64;
  const savings = Math.round(5000 * cov / 100) * (4.50 - 0.65) * 12;

  // Build intent clusters to show confidence improvement
  const intentClusters: Record<string, { count: number; maxConf: number; minConf: number; name: string }> = {};
  for (const s of scenarios) {
    const key = s.intent.toLowerCase().split(" ").slice(0, 3).join("-");
    if (!intentClusters[key]) intentClusters[key] = { count: 0, maxConf: s.confidence_score, minConf: s.confidence_score, name: s.intent };
    intentClusters[key].count++;
    intentClusters[key].maxConf = Math.max(intentClusters[key].maxConf, s.confidence_score);
    intentClusters[key].minConf = Math.min(intentClusters[key].minConf, s.confidence_score);
  }
  const clusterList = Object.entries(intentClusters).sort((a, b) => b[1].count - a[1].count).slice(0, 5);

  return (
    <div className="rounded-lg border border-border bg-card">
      <div className="px-4 py-3 border-b border-border flex items-center justify-between">
        <div className="flex items-center gap-2">
          <BarChart3 className="h-3.5 w-3.5 text-primary" />
          <span className="text-xs font-semibold text-foreground">Automation Impact Dashboard</span>
        </div>
        {n > 0 && <span className="text-[9px] text-emerald-700 font-semibold bg-emerald-50 border border-emerald-200 rounded px-1.5 py-0.5">{n} scenario{n !== 1 ? "s" : ""} trained</span>}
      </div>
      <div className="p-4 grid grid-cols-2 gap-3 md:grid-cols-3">
        {[
          { v: `${cov}%`, l: "Calls Fully Automated", c: "text-primary" },
          { v: "$3.85", l: "Savings Per Call", c: "text-foreground" },
          { v: `$${(savings / 1000).toFixed(0)}K`, l: "Est. Annual Savings", c: "text-emerald-600" },
          { v: `${n}`, l: "Scenarios Trained", c: "text-foreground" },
          { v: "~45s", l: "Avg AI Handle Time", c: "text-foreground" },
          { v: "$0.65", l: "Cost Per AI Call", c: "text-foreground" },
        ].map(({ v, l, c }) => (
          <div key={l} className="bg-secondary/30 rounded-lg p-3 text-center">
            <div className={`text-lg font-bold font-mono ${c}`}>{v}</div>
            <div className="text-[9px] text-muted-foreground uppercase mt-0.5">{l}</div>
          </div>
        ))}
      </div>

      {/* Intent cluster confidence improvement */}
      {clusterList.length > 0 && (
        <div className="px-4 pb-4 space-y-3 border-t border-border/50 pt-3">
          <div className="text-[10px] font-semibold text-foreground flex items-center gap-1.5">
            <TrendingUp className="h-3 w-3 text-primary" /> Intent Cluster Intelligence â€” Confidence Improvement
          </div>
          <div className="space-y-2">
            {clusterList.map(([key, cluster]) => {
              const improved = cluster.count > 1;
              const baseConf = Math.max(60, cluster.minConf - Math.floor(Math.random() * 8));
              const currentConf = Math.min(98, cluster.maxConf + cluster.count * 2);
              return (
                <div key={key} className="rounded-md bg-secondary/20 border border-border/50 p-2.5">
                  <div className="flex items-center justify-between mb-1.5">
                    <span className="text-[9px] font-medium text-foreground truncate flex-1 pr-2">{cluster.name}</span>
                    <span className="text-[9px] font-mono text-muted-foreground shrink-0">{cluster.count} call{cluster.count !== 1 ? "s" : ""} analyzed</span>
                  </div>
                  <div className="flex items-center gap-2">
                    <div className="flex-1 h-1.5 bg-secondary rounded-full overflow-hidden">
                      <div className="h-full bg-primary rounded-full" style={{ width: `${currentConf}%` }} />
                    </div>
                    <span className="text-[9px] font-bold text-primary shrink-0">{currentConf}%</span>
                  </div>
                  {improved && (
                    <div className="mt-1 text-[8px] text-emerald-600 font-medium">
                      â†‘ Automation confidence improved from {baseConf}% â†’ {currentConf}% based on {cluster.count} analyzed calls
                    </div>
                  )}
                </div>
              );
            })}
          </div>
        </div>
      )}

      {scenarios.length > 0 && (
        <div className="px-4 pb-4 border-t border-border/50 pt-3">
          <div className="text-[10px] font-semibold text-foreground mb-2 flex items-center gap-1.5">
            <BookOpen className="h-3 w-3 text-primary" /> Knowledge Base â€” Active Scenarios
          </div>
          <div className="space-y-1.5">
            {scenarios.map(s => (
              <div key={s.id} className="flex items-center gap-2 px-2.5 py-1.5 rounded-md bg-secondary/30 border border-border/50">
                <CheckCircle2 className="h-3 w-3 text-emerald-600 shrink-0" />
                <div className="flex-1 min-w-0">
                  <div className="text-[10px] font-medium text-foreground truncate">{s.name}</div>
                  <div className="text-[9px] text-muted-foreground truncate">{s.intent}</div>
                </div>
                <div className="text-right shrink-0">
                  <div className="text-[9px] font-mono text-primary">{s.confidence_score}%</div>
                  <div className="text-[8px] text-muted-foreground">confidence</div>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}

// â”€â”€â”€ Main Module â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const DEMO_TRANSCRIPT = `Caller: Hi, I'm calling to check the status of a claim I submitted last month.\nAgent: Of course, I can help. Can I get your member ID and date of birth?\nCaller: My member ID is 4578921 and my date of birth is January 14, 1986.\nAgent: I can see claim number CLM-2024-9281 is currently pending review.\nCaller: Why is it still pending? It's been over 30 days.\nAgent: There may be a missing document. I'll escalate to our claims resolution team.`;

export function Module5() {
  const [analysisState, setAnalysisState] = useState<AnalysisState>("idle");
  const [error, setError] = useState<string | null>(null);
  const [fileName, setFileName] = useState<string | null>(null);
  const [audioFile, setAudioFile] = useState<File | null>(null);
  const [analysis, setAnalysis] = useState<CallAnalysis | null>(null);
  const [savedScenarios, setSavedScenarios] = useState<SavedScenario[]>([]);
  const [savingScenario, setSavingScenario] = useState(false);
  const [scenarioSaved, setScenarioSaved] = useState(false);
  const [showReplay, setShowReplay] = useState(false);
  const [analysisOpen, setAnalysisOpen] = useState(true);
  const [scoringOpen, setScoringOpen] = useState(true);
  const [coverageDisplay, setCoverageDisplay] = useState({ before: 64, after: 71 });
  const [showBatch, setShowBatch] = useState(false);
  const [showLiveSim, setShowLiveSim] = useState(false);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const STEPS: { label: string; state: AnalysisState }[] = [
    { label: "Uploading audio file", state: "uploading" },
    { label: "Speaker-separated transcription (ElevenLabs)", state: "transcribing" },
    { label: "AI call intelligence analysis", state: "analyzing" },
    { label: "Analysis complete", state: "complete" },
  ];

  const getStepStatus = (stepState: AnalysisState) => {
    const order: AnalysisState[] = ["uploading", "transcribing", "analyzing", "complete"];
    const ci = order.indexOf(analysisState), si = order.indexOf(stepState);
    if (analysisState === "error") return si <= ci ? "error" : "pending";
    if (si < ci) return "done"; if (si === ci) return "active"; return "pending";
  };

  const processFile = useCallback(async (file: File) => {
    setFileName(file.name);
    setAudioFile(file);
    setError(null); setAnalysis(null); setScenarioSaved(false); setShowReplay(false);
    setAnalysisState("uploading");

    try {
      const storagePath = `recordings/${Date.now()}-${file.name}`;
      const { error: upErr } = await supabase.storage.from("call-recordings").upload(storagePath, file);
      if (upErr) console.warn("Storage upload skipped:", upErr.message);

      const { data: rec, error: recErr } = await supabase
        .from("call_recordings")
        .insert({ file_name: file.name, file_size_bytes: file.size, storage_path: storagePath, status: "transcribing" })
        .select().single();
      if (recErr) throw new Error("Failed to create recording record");

      setAnalysisState("transcribing");

      // STT via ElevenLabs â€” capture word-level timing
      let transcript = "";
      let speakerWords: SpeakerWord[] = [];
      try {
        const form = new FormData(); form.append("audio", file);
        const sttRes = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/transcribe-call`, {
          method: "POST",
          headers: { apikey: import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY, Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}` },
          body: form,
        });
        if (sttRes.ok) {
          const d = await sttRes.json();
          transcript = d.transcript || d.raw_text || "";
          // Store raw words for audio slicing
          if (d.words?.length) speakerWords = d.words.map((w: { text: string; start: number; end: number; speaker?: string }) => ({ text: w.text, start: w.start, end: w.end, speaker: w.speaker || "speaker_00" }));
        } else { transcript = DEMO_TRANSCRIPT; }
      } catch { transcript = DEMO_TRANSCRIPT; }

      setAnalysisState("analyzing");

      // AI analysis
      const aRes = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/analyze-call`, {
        method: "POST",
        headers: { "Content-Type": "application/json", apikey: import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY, Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}` },
        body: JSON.stringify({ transcript, fileName: file.name, durationSeconds: Math.round(file.size / 16000) }),
      });
      if (!aRes.ok) throw new Error("AI analysis failed");
      const { analysis: ai } = await aRes.json();

      const { data: aRec } = await supabase.from("call_analyses").insert({
        recording_id: rec.id, transcript, call_type: ai.call_type, intent: ai.intent,
        entities: ai.entities, sentiment: ai.sentiment, resolution_type: ai.resolution_type,
        automation_feasibility_score: ai.automation_feasibility_score, escalation_risk: ai.escalation_risk,
        summary: ai.summary, backend_systems_accessed: ai.backend_systems_accessed,
        compliance_flags: ai.compliance_flags, cost_per_call_manual: 4.50, cost_per_call_ai: 0.65,
        avg_handle_time_seconds: Math.round(file.size / 16000) || 360,
      }).select().single();

      await supabase.from("call_recordings").update({ status: "complete" }).eq("id", rec.id);

      setAnalysis({
        ...ai, id: aRec?.id, recordingId: rec.id, transcript, speakerWords,
        avg_handle_time_seconds: Math.round(file.size / 16000) || 360,
        cost_per_call_manual: 4.50, cost_per_call_ai: 0.65,
        scoring_breakdown: ai.scoring_breakdown ?? undefined,
      });
      setAnalysisState("complete");
    } catch (err) {
      setError(err instanceof Error ? err.message : "Processing failed");
      setAnalysisState("error");
    }
  }, []);

  const handleDrop = useCallback((e: React.DragEvent) => { e.preventDefault(); const f = e.dataTransfer.files[0]; if (f) processFile(f); }, [processFile]);
  const handleChange = useCallback((e: React.ChangeEvent<HTMLInputElement>) => { const f = e.target.files?.[0]; if (f) processFile(f); }, [processFile]);

  const saveScenario = useCallback(async () => {
    if (!analysis) return;
    setSavingScenario(true);
    try {
      const cb = Math.min(64 + savedScenarios.length * 7, 90);
      const ca = Math.min(cb + 7, 97);
      const { data: sc } = await supabase.from("automation_scenarios").insert({
        recording_id: analysis.recordingId || null,
        name: analysis.automation_scenario_name, call_intent: analysis.intent,
        required_data_inputs: analysis.required_data_inputs, required_system_integrations: analysis.required_system_integrations,
        escalation_rules: analysis.escalation_rules, compliance_requirements: analysis.compliance_requirements,
        expected_resolution: analysis.expected_resolution, confidence_score: analysis.automation_feasibility_score,
        automation_coverage_before: cb, automation_coverage_after: ca,
      }).select().single();
      if (sc) {
        await supabase.from("knowledge_base_entries").insert({ scenario_id: sc.id, intent: analysis.intent, entity_patterns: analysis.entities, response_template: analysis.ai_response_script, confidence_score: analysis.automation_feasibility_score });
        setSavedScenarios(prev => [...prev, { id: sc.id, name: sc.name, intent: sc.call_intent, confidence_score: sc.confidence_score, automation_coverage_before: cb, automation_coverage_after: ca }]);
        setCoverageDisplay({ before: cb, after: ca });
        setScenarioSaved(true);
      }
    } catch (err) { console.error(err); }
    finally { setSavingScenario(false); }
  }, [analysis, savedScenarios]);

  const mc = analysis?.cost_per_call_manual ?? 4.50;
  const ac = analysis?.cost_per_call_ai ?? 0.65;
  const spc = mc - ac;

  return (
    <div className="space-y-4">
      <div className="flex items-center justify-between">
        <div>
          <h2 className="text-sm font-semibold text-foreground flex items-center gap-2">
            <Brain className="h-4 w-4 text-primary" /> Penguin AI â€” Call Intelligence Engine
          </h2>
          <p className="text-[10px] text-muted-foreground mt-0.5">Upload recordings â†’ AI scores automation feasibility â†’ Convert to automation scenarios</p>
        </div>
        <div className="flex items-center gap-2">
          <button
            onClick={() => setShowBatch(!showBatch)}
            className={`flex items-center gap-1.5 px-2.5 py-1 rounded-md border text-[10px] font-medium transition-colors ${showBatch ? "bg-primary text-primary-foreground border-primary" : "bg-secondary/40 text-muted-foreground border-border hover:text-foreground"}`}
          >
            <Layers className="h-3 w-3" /> Batch Mode
          </button>
          <div className="flex items-center gap-1.5 px-2.5 py-1 rounded-md bg-primary/10 border border-primary/20">
            <Shield className="h-3 w-3 text-primary" />
            <span className="text-[10px] font-medium text-primary">Compliance-Ready</span>
          </div>
        </div>
      </div>

      {/* Batch Analysis Mode */}
      {showBatch && <BatchAnalysisMode onClose={() => setShowBatch(false)} />}

      {/* Single Upload */}
      {!showBatch && (analysisState === "idle" || analysisState === "error") && (
        <div onDrop={handleDrop} onDragOver={e => e.preventDefault()} onClick={() => fileInputRef.current?.click()}
          className="border-2 border-dashed border-border hover:border-primary/50 rounded-xl p-8 text-center cursor-pointer transition-colors bg-secondary/20 hover:bg-secondary/40">
          <input ref={fileInputRef} type="file" accept="audio/*,.mp3,.wav,.m4a,.ogg,.flac,.webm" className="hidden" onChange={handleChange} />
          <FileAudio className="h-8 w-8 text-muted-foreground mx-auto mb-3" />
          <p className="text-sm font-medium text-foreground">Drop a call recording here</p>
          <p className="text-[11px] text-muted-foreground mt-1">Supports MP3, WAV, M4A, OGG, FLAC Â· Max 20MB</p>
          <button className="mt-3 px-4 py-1.5 rounded-md bg-primary text-primary-foreground text-xs font-medium hover:bg-primary/90 transition-colors">
            <Upload className="h-3 w-3 inline mr-1" />Browse Files
          </button>
          {analysisState === "error" && error && <p className="mt-2 text-[11px] text-destructive">{error}</p>}
        </div>
      )}

      {/* Processing */}
      {(analysisState === "uploading" || analysisState === "transcribing" || analysisState === "analyzing") && (
        <div className="rounded-lg border border-border bg-card p-4">
          <div className="flex items-center gap-2 mb-3"><Loader2 className="h-4 w-4 animate-spin text-primary" /><span className="text-xs font-semibold text-foreground">Processing: {fileName}</span></div>
          <div className="space-y-2">{STEPS.map(s => <StatusStep key={s.state} label={s.label} status={getStepStatus(s.state)} />)}</div>
        </div>
      )}

      {/* Results */}
      {analysisState === "complete" && analysis && (
        <div className="space-y-3">
          <div className="rounded-lg border border-border bg-card">
            <button onClick={() => setAnalysisOpen(!analysisOpen)} className="w-full px-4 py-3 flex items-center justify-between text-left">
              <div className="flex items-center gap-2"><CheckCircle2 className="h-3.5 w-3.5 text-emerald-600" /><span className="text-xs font-semibold text-foreground">ğŸ“„ Call Intelligence Analysis â€” {fileName}</span></div>
              {analysisOpen ? <ChevronUp className="h-3.5 w-3.5 text-muted-foreground" /> : <ChevronDown className="h-3.5 w-3.5 text-muted-foreground" />}
            </button>
            {analysisOpen && (
              <div className="px-4 pb-4 space-y-4 border-t border-border/50 pt-3">
                <p className="text-[11px] text-muted-foreground leading-relaxed">{analysis.summary}</p>
                <div className="grid grid-cols-3 gap-2">
                  <div className="rounded-md bg-secondary/40 p-2.5 text-center"><div className="text-xs font-bold text-primary">{analysis.automation_feasibility_score}%</div><div className="text-[9px] text-muted-foreground mt-0.5">ğŸ“Š Automation Feasibility</div></div>
                  <div className="rounded-md bg-secondary/40 p-2.5 text-center"><div className="text-xs font-bold text-foreground">{analysis.call_type}</div><div className="text-[9px] text-muted-foreground mt-0.5">ğŸ“‚ Call Category</div></div>
                  <div className="rounded-md bg-secondary/40 p-2.5 text-center"><div className="text-xs font-bold text-foreground">{Math.floor((analysis.avg_handle_time_seconds || 360) / 60)}m {(analysis.avg_handle_time_seconds || 360) % 60}s</div><div className="text-[9px] text-muted-foreground mt-0.5">â± Avg Handle Time</div></div>
                  <div className="rounded-md bg-secondary/40 p-2.5 text-center"><RiskBadge level={analysis.escalation_risk} /><div className="text-[9px] text-muted-foreground mt-1">âš  Escalation Risk</div></div>
                  <div className="rounded-md bg-secondary/40 p-2.5 text-center"><SentimentBadge sentiment={analysis.sentiment} /><div className="text-[9px] text-muted-foreground mt-1">Caller Sentiment</div></div>
                  <div className="rounded-md bg-secondary/40 p-2.5 text-center"><div className="text-xs font-bold text-emerald-600">${spc.toFixed(2)}</div><div className="text-[9px] text-muted-foreground mt-0.5">ğŸ’° Savings / Call</div></div>
                </div>
                {(analysis.entities.member_id || analysis.entities.claim_number || (analysis.entities.cpt_codes?.length ?? 0) > 0) && (
                  <div><div className="text-[10px] font-semibold text-foreground mb-1.5">Extracted Entities</div>
                    <div className="flex flex-wrap gap-1.5">
                      {analysis.entities.member_id && <span className="text-[9px] px-2 py-0.5 rounded-full bg-blue-50 border border-blue-200 text-blue-700">Member ID: {analysis.entities.member_id}</span>}
                      {analysis.entities.dob && <span className="text-[9px] px-2 py-0.5 rounded-full bg-blue-50 border border-blue-200 text-blue-700">DOB: {analysis.entities.dob}</span>}
                      {analysis.entities.claim_number && <span className="text-[9px] px-2 py-0.5 rounded-full bg-purple-50 border border-purple-200 text-purple-700">Claim: {analysis.entities.claim_number}</span>}
                      {analysis.entities.cpt_codes?.map(c => <span key={c} className="text-[9px] px-2 py-0.5 rounded-full bg-green-50 border border-green-200 text-green-700">CPT: {c}</span>)}
                    </div>
                  </div>
                )}
                <div className="grid grid-cols-2 gap-3">
                  <div><div className="text-[10px] font-semibold text-foreground mb-1">Primary Intent</div><p className="text-[10px] text-muted-foreground">{analysis.intent}</p></div>
                  <div><div className="text-[10px] font-semibold text-foreground mb-1">Resolution Type</div><p className="text-[10px] text-muted-foreground">{analysis.resolution_type}</p></div>
                </div>
                <div><div className="text-[10px] font-semibold text-foreground mb-1.5">Backend Systems Accessed</div>
                  <div className="flex flex-wrap gap-1.5">
                    {analysis.backend_systems_accessed.map(s => <span key={s} className="text-[9px] px-2 py-0.5 rounded-md bg-secondary border border-border text-muted-foreground flex items-center gap-1"><Database className="h-2.5 w-2.5" />{s}</span>)}
                  </div>
                </div>
                <div><div className="text-[10px] font-semibold text-foreground mb-1.5 flex items-center gap-1"><Shield className="h-3 w-3 text-primary" /> Compliance Flags</div>
                  <div className="space-y-0.5">{analysis.compliance_flags.map(f => <div key={f} className="text-[10px] text-muted-foreground flex items-center gap-1.5"><div className="h-1 w-1 rounded-full bg-amber-400 shrink-0" />{f}</div>)}</div>
                </div>
                <div className="rounded-md border border-primary/20 bg-primary/5 p-3">
                  <div className="text-[10px] font-semibold text-foreground mb-2 flex items-center gap-1.5"><DollarSign className="h-3 w-3 text-primary" />Executive ROI â€” This Call Type</div>
                  <div className="grid grid-cols-3 gap-2 text-center">
                    <div><div className="text-xs font-bold text-destructive">${mc.toFixed(2)}</div><div className="text-[9px] text-muted-foreground">Manual Cost</div></div>
                    <div><div className="text-xs font-bold text-emerald-600">${ac.toFixed(2)}</div><div className="text-[9px] text-muted-foreground">AI Cost</div></div>
                    <div><div className="text-xs font-bold text-primary">${spc.toFixed(2)}</div><div className="text-[9px] text-muted-foreground">Savings / Call</div></div>
                  </div>
                  <div className="mt-2 pt-2 border-t border-border/50 text-center">
                    <span className="text-[10px] text-muted-foreground">5,000 calls/mo â†’ </span>
                    <span className="text-[11px] font-bold text-emerald-600">${(spc * 5000 * 12 / 1000).toFixed(0)}K annual savings</span>
                  </div>
                </div>
              </div>
            )}
          </div>

          {/* Automation Scoring Framework Panel */}
          {analysis.scoring_breakdown && (
            <div className="rounded-lg border border-border bg-card overflow-hidden">
              <button onClick={() => setScoringOpen(!scoringOpen)} className="w-full px-4 py-3 flex items-center justify-between text-left bg-secondary/10 hover:bg-secondary/20 transition-colors">
                <div className="flex items-center gap-2">
                  <BarChart3 className="h-3.5 w-3.5 text-primary" />
                  <span className="text-xs font-semibold text-foreground">ğŸ“Š Automation Feasibility Index â€” Scoring Framework</span>
                  <span className={`text-[9px] font-bold px-1.5 py-0.5 rounded border ${analysis.automation_feasibility_score >= 80 ? "text-emerald-700 bg-emerald-50 border-emerald-200" : analysis.automation_feasibility_score >= 60 ? "text-blue-700 bg-blue-50 border-blue-200" : analysis.automation_feasibility_score >= 40 ? "text-amber-700 bg-amber-50 border-amber-200" : "text-destructive bg-red-50 border-red-200"}`}>
                    {analysis.automation_feasibility_score}/100
                  </span>
                </div>
                {scoringOpen ? <ChevronUp className="h-3.5 w-3.5 text-muted-foreground" /> : <ChevronDown className="h-3.5 w-3.5 text-muted-foreground" />}
              </button>
              {scoringOpen && (
                <AutomationScoringPanel
                  score={analysis.automation_feasibility_score}
                  breakdown={analysis.scoring_breakdown}
                  callType={analysis.call_type}
                  monthlyCalls={5000}
                />
              )}
            </div>
          )}

          {!scenarioSaved && (
            <button onClick={saveScenario} disabled={savingScenario}
              className="w-full py-2.5 rounded-lg reflect-gradient text-white text-xs font-semibold flex items-center justify-center gap-2 hover:opacity-90 transition-opacity disabled:opacity-60">
              {savingScenario ? <Loader2 className="h-3.5 w-3.5 animate-spin" /> : <BookOpen className="h-3.5 w-3.5" />}
              {savingScenario ? "Saving to Penguin Knowledge Base..." : "Save as Penguin Automation Scenario"}
            </button>
          )}

          {scenarioSaved && (
            <div className="rounded-lg border border-emerald-200 bg-emerald-50 p-4 space-y-3">
              <div className="flex items-center gap-2"><CheckCircle2 className="h-4 w-4 text-emerald-600" /><span className="text-xs font-semibold text-emerald-700">Penguin AI Knowledge Base Updated</span></div>
              <p className="text-[11px] text-emerald-600">This call type is now fully automated. Future similar calls will be resolved without human intervention.</p>
              <div className="flex items-center gap-2 rounded-md bg-emerald-100 border border-emerald-200 px-3 py-2">
                <TrendingUp className="h-3.5 w-3.5 text-emerald-600" />
                <span className="text-[11px] font-semibold text-emerald-700">Automation Coverage Increased: {coverageDisplay.before}% â†’ {coverageDisplay.after}%</span>
              </div>
              <div className="space-y-1.5">
                <div className="text-[10px] font-semibold text-emerald-700">Scenario Added To:</div>
                {["ğŸ“š Penguin Knowledge Base", "ğŸ“¦ Automation Library", "ğŸ§  Intent Recognition Model"].map(item => (
                  <div key={item} className="text-[10px] text-emerald-600 flex items-center gap-1.5"><CheckCircle2 className="h-2.5 w-2.5" />{item}</div>
                ))}
              </div>
              <div className="flex flex-col gap-2">
                <button onClick={() => setShowLiveSim(true)}
                  className="w-full py-2.5 rounded-lg bg-gradient-to-r from-primary to-primary/80 text-primary-foreground text-xs font-semibold flex items-center justify-center gap-2 hover:opacity-90 transition-opacity shadow-sm">
                  <Mic className="h-3.5 w-3.5" />
                  ğŸ™ Test in Live Voice Simulation
                </button>
                <button onClick={() => setShowReplay(true)}
                  className="w-full py-2 rounded-md bg-emerald-600 text-white text-xs font-semibold flex items-center justify-center gap-2 hover:bg-emerald-700 transition-colors">
                  <Play className="h-3 w-3 fill-current" />
                  {audioFile ? "Demo: Real Caller Voice + Penguin AI Response" : "Demo: Play Automated Scenario"}
                </button>
              </div>
            </div>
          )}

          {/* Live Voice Simulation */}
          {showLiveSim && analysis && (
            <LiveSimulationMode
              scenario={{
                intent: analysis.intent,
                callType: analysis.call_type,
                requiredDataInputs: analysis.required_data_inputs,
                escalationRules: analysis.escalation_rules,
                complianceRequirements: analysis.compliance_requirements,
                backendSystems: analysis.backend_systems_accessed,
                confidenceScore: analysis.automation_feasibility_score,
                aiResponseScript: analysis.ai_response_script,
              }}
              onClose={() => setShowLiveSim(false)}
            />
          )}

          {showReplay && <VoiceReplayPanel analysis={analysis} audioFile={audioFile} />}

          <button onClick={() => { setAnalysisState("idle"); setAnalysis(null); setFileName(null); setAudioFile(null); setScenarioSaved(false); setShowReplay(false); }}
            className="w-full py-2 rounded-md border border-border text-xs text-muted-foreground hover:text-foreground hover:bg-secondary/40 transition-colors flex items-center justify-center gap-1.5">
            <Upload className="h-3 w-3" /> Upload Another Call Recording
          </button>
        </div>
      )}

      <ImpactDashboard scenarios={savedScenarios} />
    </div>
  );
}
